{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a220719b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to my Kaggle Titanic Machine Learning Challenge notebook, a journey into the world of data science and predictive modeling. In this competition, we aim to build a robust machine learning model that predicts the survival of passengers aboard the ill-fated RMS Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12724f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890b4c2",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3afce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/r162x_ld4ydb57pdv1b88jh00000gn/T/ipykernel_7128/2937487608.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nn_df['CabinType'] = codes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def preprocess_df(df):\n",
    "    def tokenize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def clean_and_convert(value):\n",
    "        if isinstance(value, str):\n",
    "            if value.strip():  # Check if the string is not empty after stripping whitespace\n",
    "                # Use regular expression to remove non-numeric characters\n",
    "                cleaned_value = re.sub(r'[^0-9.]', '', value)\n",
    "                # Convert the cleaned value to float\n",
    "                return float(cleaned_value)\n",
    "            else:\n",
    "                # Return NaN for empty strings\n",
    "                return np.nan\n",
    "        else:\n",
    "            # If it's not a string, return it as is\n",
    "            return value\n",
    "\n",
    "\n",
    "    def ticket_number(x):\n",
    "        last_part = x.split(\" \")[-1]\n",
    "        numeric_part = re.sub(r'[^0-9.]', '', last_part)  # Allow for decimal point\n",
    "        if numeric_part == \"\":\n",
    "            return float('nan')\n",
    "        else:\n",
    "            return float(numeric_part)\n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "\n",
    "    \n",
    "\n",
    "    df['Name'] = df['Name'].apply(tokenize_name)\n",
    "    # Extract surnames from the \"Name\" column\n",
    "    df['Surname'] = df['Name'].apply(lambda x: x.split(',')[0].strip())\n",
    "    \n",
    "    # Create a new column for family size\n",
    "    df['Family_Size'] = df.groupby('Surname')['Surname'].transform('count')\n",
    "\n",
    "    # Add 1 to include the person with that surname itself\n",
    "    df['Family_Size'] = df['Family_Size'] + 1\n",
    "    \n",
    "    # Add ticket number Column\n",
    "    df[\"TicketNumber\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "\n",
    "    df[\"TicketItem\"] = df[\"Ticket\"].apply(ticket_item) \n",
    "\n",
    "\n",
    "    # Encode the Cabin Type as a Feature and One-hot encode Sex and Embarked columns\n",
    "    df['CabinType'] = df['Cabin'].str[0]\n",
    "\n",
    "    df['CabinNumber'] = df['Cabin'].str[1:]\n",
    "    df['CabinNumber'] = df['CabinNumber'].apply(clean_and_convert)\n",
    "\n",
    "    # Replace NaN values with 0 in the 'CabinNumber' column\n",
    "    df['CabinNumber'].fillna(df['CabinNumber'].median(), inplace=True)\n",
    "\n",
    "    # One-hot encode sex and embarking location of the catgeorical columns\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], dtype=int)\n",
    "    \n",
    "    # Also include a column representing if a passeneger has a column\n",
    "    #df['HasCabin'] = np.where(df['Cabin'].isna(), 0, 1)\n",
    "\n",
    "\n",
    "    # Age column has several NaN values. Augment these with median age instead of removing\n",
    "    median_age = df['Age'].median()\n",
    "    df['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "    # One-hot encode the titles which occur three or more times into features\n",
    "    titles_to_encode = ['Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev']\n",
    "\n",
    "    # Create new columns for each title and encode as 1 if the title is present, 0 otherwise\n",
    "    for title in titles_to_encode:\n",
    "        df[title] = df['Name'].apply(lambda x: 1 if title in x else 0)\n",
    "\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    df.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', 'Surname', 'TicketNumber', 'TicketItem'], axis=1, inplace=True)\n",
    "\n",
    "    # Assuming 'CabinType' is the target column to impute\n",
    "    target_column = 'CabinType'\n",
    "\n",
    "    # Create a DataFrame for training set (rows with non-NaN values)\n",
    "    nn_df = df.dropna(subset=[target_column])\n",
    "\n",
    "    # Create a DataFrame for the target set (rows with NaN values)\n",
    "    target_df = df[df[target_column].isna()]\n",
    "\n",
    "    # Encode 'CabinType' values (assuming they are categorical)\n",
    "    codes = nn_df['CabinType'].astype('category').cat.codes\n",
    "    nn_df['CabinType'] = codes\n",
    "\n",
    "    # Initialize and fit KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)  # You can adjust the number of neighbors\n",
    "    knn.fit(nn_df.drop(columns=[target_column]), nn_df[target_column])\n",
    "\n",
    "    # Predict 'CabinType' values for the rows with NaN values\n",
    "    predicted_values = knn.predict(target_df.drop(columns=[target_column]))\n",
    "\n",
    "    # Update the 'CabinType' values for the rows where it was not NaN\n",
    "    df.loc[df[target_column].notnull(), target_column] = codes[df[target_column].notnull()]\n",
    "\n",
    "    # Assign the predicted values to the corresponding rows where 'CabinType' is NaN\n",
    "    df.loc[df[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess_df(data)\n",
    "\n",
    "\n",
    "# Step 1: Split the data into training and test sets\n",
    "X = train_df.drop(columns=['Survived'])  # Features (all columns except 'Survived')\n",
    "y = train_df['Survived']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into 80% training and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both the training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ecebb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      2\n",
       "2      3\n",
       "3      2\n",
       "4      3\n",
       "      ..\n",
       "886    3\n",
       "887    1\n",
       "888    2\n",
       "889    2\n",
       "890    3\n",
       "Name: CabinType, Length: 891, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['CabinType']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912be113",
   "metadata": {},
   "source": [
    "## Train Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9887d3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.810\n",
      "Decision Tree Accuracy: 0.810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.804\n",
      "SVM Accuracy: 0.810\n",
      "GBDT Accuracy: 0.810\n",
      "XGBoost Accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'GBDT': GradientBoostingClassifier(random_state=42),  # Add GBDT\n",
    "    'XGBoost': XGBClassifier(random_state=42)  # Add XGBoost\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_scaled, y_train)  # Train the model\n",
    "    y_pred = classifier.predict(X_test_scaled)  # Make predictions on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    print(f'{name} Accuracy: {accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf69d3",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50910553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "# Define a parameter grid for GBDT hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting model\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create an instance of GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=6, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV instance on the training data\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Retrieve the best hyperparameters and the corresponding best estimator\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "best_rf_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3518f0",
   "metadata": {},
   "source": [
    "## Predict on Unseen Testing Set with Optimised Cross-Validated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "31a3fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/r162x_ld4ydb57pdv1b88jh00000gn/T/ipykernel_7128/2937487608.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nn_df['CabinType'] = codes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Fare column has several NaN values. Augment these with median fare instead of removing\n",
    "median_fare = test_df['Fare'].median()\n",
    "test_df['Fare'].fillna(median_fare, inplace=True)\n",
    "\n",
    "test_df_processed = preprocess_df(test_df)\n",
    "\n",
    "# Select features and scale unseen data\n",
    "X_test = test_df_processed.copy()  # Features (all columns except 'Survived')\n",
    "\n",
    "ordered_cols = X.columns\n",
    "\n",
    "# Add columns that have been missed during one-hot encdoing due to the test data not containing certain categories etc\n",
    "missing_cols = set(X.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "\n",
    "# Re-order columns to be in the same order as for the training data\n",
    "X_test = X_test[ordered_cols]\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "preds = best_rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Create Data Frame with Passenger ID and Prediction\n",
    "final_predictions = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': preds})\n",
    "\n",
    "final_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3e50f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as csv file\n",
    "final_predictions.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
